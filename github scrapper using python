from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time

scrape = input("what page would you like to scrape? ")
cdp = "/home/dehant/Desktop/cw/chromedriver-linux64/chromedriver"

service = Service(executable_path = cdp)
driver = webdriver.Chrome(service=service)

driver.get(f"{scrape}")
print(f"scraping this: {scrape}")

repo = "https://github.com/usernam121"

time.sleep(2)

rep = driver.find_elements(By.CLASS_NAME, "repo")
print("repos found! ", len(rep))

links = []


def going_for_raw(second_page):
    print(f"going for this {second_page}")
    driver.get(second_page)

    try:
        raw = driver.find_element(By.XPATH, "//a[contains(@href, 'raw')]")
        raw.click()

        time.sleep(2)
        html = driver.page_source
        if "password"  in html:
            print(f"Found password in {second_page}")
        else:
            return

    except Exception as e:
        print(e)


def page_1(first_page):
    print(f"getting this now: {first_page}")
    driver.get(first_page)
    time.sleep(2)
    print(f"got this: {first_page}")

    rep2 = driver.find_elements(By.CLASS_NAME, "Link--primary")
    file_names = [q.text for q in rep2 if ".py" in q.text.lower()]

    for filename  in file_names:
       second_page = f"{first_page}/blob/main/{filename}"
       print(f"we got this: {second_page}")
       going_for_raw(second_page)


for i in rep:
    links.append(i.text)
    print(f"Here are the links: {links}")

for l in links:
    first_page = f"{repo}/{l}"
    print(f"here is the first page: {first_page}")
    page_1(first_page)


driver.quit()







